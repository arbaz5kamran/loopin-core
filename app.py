import os

# Gevent monkey patching must happen BEFORE other imports that use SSL
try:
    import gevent.monkey
    gevent.monkey.patch_all()
    if os.getenv("FLASK_ENV") == "development":
        print("‚úÖ Gevent monkey patching applied early (prevents SSL warnings)")
except ImportError:
    if os.getenv("FLASK_ENV") == "development":
        print("INFO: Gevent not available")
import time
import uuid
import pytz
import re
import logging
from datetime import datetime, timedelta
from urllib.parse import urlparse

from dotenv import load_dotenv
from flask import Flask, current_app, render_template, request, redirect, url_for, flash, session, jsonify, send_file
from flask_sqlalchemy import SQLAlchemy
from sqlalchemy import text, func, or_
from werkzeug.security import generate_password_hash, check_password_hash
from functools import wraps
from flask_migrate import Migrate
from read_logs import bp as read_logs_bp
from flask_login import LoginManager
from models import User, Update, ReadLog, SOPSummary, LessonLearned, ActivityLog, ArchivedUpdate, ArchivedSOPSummary, ArchivedLessonLearned
from extensions import db, socketio
from role_decorators import admin_required, editor_required, writer_required, delete_required, export_required, get_user_role_info
from timezone_utils import UTC, IST, now_utc, to_utc, to_ist, format_ist, ensure_timezone, is_within_hours, get_hours_ago
from io import BytesIO
import sys
import subprocess
from pathlib import Path

# Add system Python site-packages to path if needed (for environments with path issues)
try:
    import site
    # Get all site-packages directories and add them to path if not already present
    site_packages_dirs = site.getsitepackages()
    for site_dir in site_packages_dirs:
        if site_dir not in sys.path and os.path.exists(site_dir):
            sys.path.insert(0, site_dir)
except Exception:
    # Fallback: try common site-packages locations
    import platform
    python_version = f"Python{sys.version_info.major}{sys.version_info.minor}"
    if platform.system() == "Windows":
        possible_paths = [
            os.path.join(os.path.dirname(sys.executable), "Lib", "site-packages"),
            os.path.expanduser(f"~\\AppData\\Local\\Programs\\Python\\{python_version}\\Lib\\site-packages"),
            os.path.expanduser(f"~\\AppData\\Roaming\\Python\\Python{sys.version_info.major}{sys.version_info.minor}\\site-packages")
        ]
        for path in possible_paths:
            if path not in sys.path and os.path.exists(path):
                sys.path.insert(0, path)
                break

# Import pandas and openpyxl with error handling
try:
    import pandas as pd
    import openpyxl
    EXCEL_EXPORT_AVAILABLE = True
except ImportError as e:
    # Only print warning in development mode
    if os.getenv('FLASK_ENV') == 'development':
        print(f"Warning: Excel export dependencies not available: {e}")
    EXCEL_EXPORT_AVAILABLE = False

# Load .env
load_dotenv()

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

migrate = Migrate()
login_manager = LoginManager()
login_manager.login_view = 'login'

# Process start timestamp for basic metrics
APP_START = time.time()

def create_app(config_name=None):
    app = Flask(__name__)
    migrate.init_app(app, db)
    login_manager.init_app(app)
    socketio.init_app(app)
    app.register_blueprint(read_logs_bp)
    # Register new API blueprint (first milestone)
    try:
        from api.updates import bp as api_bp
        app.register_blueprint(api_bp)
    except Exception:
        # Blueprint registration should not break app startup if something is off
        pass
    
    # Register Socket.IO blueprint for real-time updates
    try:
        from api.socketio import bp as socketio_bp, init_socketio
        app.register_blueprint(socketio_bp)
        init_socketio(socketio, app)
        if os.getenv("FLASK_ENV") == "development":
            print("SUCCESS: Socket.IO blueprint registered successfully")
    except Exception as e:
        # Socket.IO registration should not break app startup if something is off
        if os.getenv("FLASK_ENV") == "development":
            print(f"WARNING: Socket.IO blueprint registration failed: {e}")
            import traceback
            print(f"WARNING: Full error: {traceback.format_exc()}")
        pass
    
    # Register search API blueprint
    try:
        from api.search import bp as search_bp
        app.register_blueprint(search_bp)
    except Exception:
        # Search API registration should not break app startup if something is off
        pass

    @login_manager.user_loader
    def load_user(user_id):
        return User.query.get(int(user_id))

    # Security configuration
    app.secret_key = os.getenv("FLASK_SECRET_KEY", "replace-this-with-a-secure-random-string")
    app.config["APP_NAME"] = "LoopIn"

    # CORS configuration for Socket.IO
    app.config["CORS_HEADERS"] = "Content-Type"

    # Secure session configuration - adjust for Railway
    is_production = os.getenv("RAILWAY_ENVIRONMENT") == "production" or os.getenv("FLASK_ENV") == "production"
    if is_production:
        app.config["SESSION_COOKIE_SECURE"] = True  # Only send cookies over HTTPS
    else:
        app.config["SESSION_COOKIE_SECURE"] = False  # Allow HTTP for development
    app.config["SESSION_COOKIE_HTTPONLY"] = True  # Prevent JavaScript access to session cookie
    app.config["SESSION_COOKIE_SAMESITE"] = "Lax"  # CSRF protection
    app.config["PERMANENT_SESSION_LIFETIME"] = 3600  # Session timeout in seconds

    # Railway-specific configurations
    if os.getenv("RAILWAY_ENVIRONMENT"):
        app.config["SERVER_NAME"] = None  # Disable SERVER_NAME for Railway
        app.config["PREFERRED_URL_SCHEME"] = "https"  # Force HTTPS on Railway

        # Additional Railway configurations for Socket.IO
        app.config["RAILWAY_STATIC_URL"] = os.getenv("RAILWAY_STATIC_URL", "")

        # Log Railway environment info (only in development)
        if os.getenv("FLASK_ENV") == "development":
            print(f"üöÇ Railway Environment: {os.getenv('RAILWAY_ENVIRONMENT')}")
            print(f"üöÇ Railway Project ID: {os.getenv('RAILWAY_PROJECT_ID', 'Not set')}")
            print(f"üöÇ Railway Service ID: {os.getenv('RAILWAY_SERVICE_ID', 'Not set')}")
            print(f"üöÇ Railway Public Domain: {os.getenv('RAILWAY_PUBLIC_DOMAIN', 'Not set')}")
            print(f"üöÇ Railway WebSocket Support: {os.getenv('RAILWAY_WEBSOCKET_SUPPORT', 'Not set')}")
            print(f"üöÇ Railway Git Commit SHA: {os.getenv('RAILWAY_GIT_COMMIT_SHA', 'Not set')}")
            print(f"üöÇ Railway Git Branch: {os.getenv('RAILWAY_GIT_BRANCH', 'Not set')}")

    # Database configuration
    database_url = os.getenv("DATABASE_URL")
    if not database_url:
        database_url = "sqlite:///loopin.db"
        if os.getenv("FLASK_ENV") == "development":
            print("‚ö†Ô∏è DATABASE_URL not set, using SQLite by default")
    else:
        if os.getenv("FLASK_ENV") == "development":
            print("Using database from DATABASE_URL")

    parsed = urlparse(database_url)
    if parsed.scheme not in ("postgresql", "postgres", "sqlite", "sqlite3"):
        raise RuntimeError(f"Unsupported DB scheme: {parsed.scheme}")

    app.config["SQLALCHEMY_DATABASE_URI"] = database_url
    app.config["SQLALCHEMY_TRACK_MODIFICATIONS"] = False

    # Configure SSL for PostgreSQL if needed
    if os.getenv("PG_SSLMODE") and parsed.scheme in ("postgresql", "postgres"):
        app.config["SQLALCHEMY_ENGINE_OPTIONS"] = {
            "connect_args": {"sslmode": os.getenv("PG_SSLMODE")}
        }

    db.init_app(app)

    with app.app_context():
        if os.getenv("FLASK_ENV") == "development":
            print("Database configured successfully")

        # Verify database connection and table reflection
        try:
            # Test basic connection
            db.session.execute(text("SELECT 1"))
            logger.info("‚úÖ Database connection successful")

            # Check if tables exist
            from sqlalchemy import inspect
            inspector = inspect(db.engine)
            existing_tables = inspector.get_table_names()
            expected_tables = ['users', 'updates', 'read_logs', 'activity_logs', 'archived_updates', 'archived_sop_summaries', 'archived_lessons_learned', 'sop_summaries', 'lessons_learned']

            logger.info(f"üìã Existing tables: {existing_tables}")
            logger.info(f"üéØ Expected tables: {expected_tables}")

            missing_tables = [table for table in expected_tables if table not in existing_tables]
            if missing_tables:
                logger.warning(f"‚ö†Ô∏è Missing tables: {missing_tables}")
            else:
                logger.info("‚úÖ All expected tables are present")

            # Test a simple query on users table
            user_count = User.query.count()
            logger.info(f"üë• Users table has {user_count} records")

        except Exception as e:
            logger.error(f"‚ùå Database verification failed: {e}")
            if os.getenv("FLASK_ENV") == "development":
                print(f"‚ùå Database verification failed: {e}")

    # Activity Logging Helper
    def log_activity(action, entity_type, entity_id, entity_title=None, details=None):
        """Log user activity for audit trail"""
        try:
            user_id = session.get("user_id")

            # Get client IP address
            client_ip = request.environ.get('HTTP_X_FORWARDED_FOR', request.environ.get('REMOTE_ADDR', 'Unknown'))
            if ',' in client_ip:
                client_ip = client_ip.split(',')[0].strip()

            # Get user agent
            user_agent = request.headers.get('User-Agent', 'Unknown')

            activity = ActivityLog(
                user_id=user_id,
                action=action,
                entity_type=entity_type,
                entity_id=str(entity_id),
                entity_title=entity_title,
                timestamp=now_utc(),
                ip_address=client_ip,
                user_agent=user_agent,
                details=details
            )

            db.session.add(activity)
            db.session.commit()
        except Exception as e:
            # Don't let activity logging break the main functionality
            if os.getenv("FLASK_ENV") == "development":
                print(f"Activity logging failed: {e}")

    # Archive Helper Functions
    def archive_update(update):
        """Archive an update before deletion"""
        try:
            # Validate update object
            if not update or not update.id:
                raise ValueError("Invalid update object")

            # Get archiving user
            user_id = session.get("user_id")
            if not user_id:
                app.logger.warning("Archiving update without user context")

            # Check if already archived
            existing_archive = ArchivedUpdate.query.get(update.id)
            if existing_archive:
                app.logger.warning(f"Update {update.id} already archived")
                return True

            # Create archive record
            archived_update = ArchivedUpdate(
                id=update.id,
                name=update.name,
                process=update.process,
                message=update.message,
                timestamp=update.timestamp,
                archived_at=now_utc(),
                archived_by=user_id
            )

            # Save the archive
            db.session.add(archived_update)
            db.session.commit()
            
            app.logger.info(f"Successfully archived update {update.id}")
            return True
        except Exception as e:
            db.session.rollback()
            app.logger.error(f"Failed to archive update {update.id if update and hasattr(update, 'id') else 'unknown'}: {str(e)}")
            return False

    def archive_sop(sop):
        """Archive a SOP before deletion"""
        try:
            # Validate SOP object
            if not sop or not sop.id:
                raise ValueError("Invalid SOP object")

            # Get archiving user
            user_id = session.get("user_id")
            if not user_id:
                app.logger.warning("Archiving SOP without user context")

            # Check if already archived
            existing_archive = ArchivedSOPSummary.query.get(sop.id)
            if existing_archive:
                app.logger.warning(f"SOP {sop.id} already archived")
                return True

            # Create archive record
            archived_sop = ArchivedSOPSummary(
                id=sop.id,
                title=sop.title,
                summary_text=sop.summary_text,
                department=sop.department,
                tags=sop.tags,
                created_at=sop.created_at,
                archived_at=now_utc(),
                archived_by=user_id
            )

            # Save the archive
            db.session.add(archived_sop)
            db.session.commit()
            
            app.logger.info(f"Successfully archived SOP {sop.id}")
            return True
        except Exception as e:
            db.session.rollback()
            app.logger.error(f"Failed to archive SOP {sop.id if sop and hasattr(sop, 'id') else 'unknown'}: {str(e)}")
            return False

    def archive_lesson(lesson):
        """Archive a lesson learned before deletion"""
        try:
            # Validate lesson object
            if not lesson or not lesson.id:
                raise ValueError("Invalid lesson object")

            # Get archiving user
            user_id = session.get("user_id")
            if not user_id:
                app.logger.warning("Archiving lesson without user context")

            # Check if already archived
            existing_archive = ArchivedLessonLearned.query.get(lesson.id)
            if existing_archive:
                app.logger.warning(f"Lesson {lesson.id} already archived")
                return True

            # Create archive record
            archived_lesson = ArchivedLessonLearned(
                id=lesson.id,
                title=lesson.title,
                content=lesson.content,
                summary=lesson.summary,
                author=lesson.author,
                department=lesson.department,
                tags=lesson.tags,
                created_at=lesson.created_at,
                archived_at=now_utc(),
                archived_by=user_id
            )

            # Save the archive
            db.session.add(archived_lesson)
            db.session.commit()
            
            app.logger.info(f"Successfully archived lesson {lesson.id}")
            return True
        except Exception as e:
            db.session.rollback()
            app.logger.error(f"Failed to archive lesson {lesson.id if lesson and hasattr(lesson, 'id') else 'unknown'}: {str(e)}")
            return False

    # Auth Helpers
    def login_required(f):
        @wraps(f)
        def decorated(*args, **kwargs):
            if not session.get("user_id"):
                flash("üîí Please log in to continue.")
                return redirect(url_for("login", next=request.endpoint))
            return f(*args, **kwargs)
        return decorated

    @app.context_processor
    def inject_current_user():
        user = None
        if session.get("user_id"):
            user = User.query.get(session["user_id"])
        return dict(current_user=user)

    @app.context_processor
    def inject_user_role_info():
        """
        Inject user role information into templates for conditional rendering.
        """
        user = None
        if session.get("user_id"):
            user = User.query.get(session["user_id"])
        role_info = get_user_role_info(user)
        return dict(user_role=role_info)

    @app.context_processor
    def inject_now_utc():
        """Make now_utc function available in templates"""
        return dict(now_utc=now_utc)

    @app.template_filter('to_ist')
    def to_ist_filter(utc_datetime):
        """Convert UTC datetime to IST for display"""
        return format_ist(utc_datetime, '%Y-%m-%d %H:%M')

    @app.template_filter('format_datetime')
    def format_datetime_filter(dt, format='%Y-%m-%d %H:%M'):
        """Format datetime with timezone conversion"""
        return format_ist(dt, format)

    @app.template_filter('format_backup_timestamp')
    def format_backup_timestamp_filter(iso_string):
        """Convert ISO timestamp string to IST for backup display"""
        if not iso_string:
            return 'N/A'
        try:
            # Parse the ISO string to datetime
            from datetime import datetime
            # Handle different ISO formats
            if iso_string.endswith('Z'):
                iso_string = iso_string.replace('Z', '+00:00')
            elif '+' not in iso_string and 'T' in iso_string:
                # Assume UTC if no timezone info
                iso_string = iso_string + '+00:00'

            dt = datetime.fromisoformat(iso_string)
            # Convert to IST and format
            return format_ist(dt, '%Y-%m-%d %H:%M:%S')
        except (ValueError, AttributeError, TypeError):
            # Fallback to original string manipulation if parsing fails
            try:
                return iso_string[:19].replace('T', ' ') + ' (UTC)'
            except:
                return str(iso_string)

    @app.context_processor
    def built_assets_available():
        """Expose a small flag to templates indicating whether built CSS exists.

        Templates can use `built_css` to prefer a local built stylesheet
        (e.g. `static/dist/styles.css`) when present, otherwise fall back
        to a CDN link. This keeps CI builds optional and safe for local dev.
        """
        try:
            static_path = os.path.join(app.root_path, "static", "dist", "styles.css")
            is_prod = str(app.config.get('ENV', '')).lower() == 'production' or os.getenv('FLASK_ENV', '').lower() == 'production' or os.getenv('ENV', '').lower() == 'production'
            return dict(built_css=os.path.exists(static_path), is_production=is_prod)
        except Exception:
            return dict(built_css=False, is_production=False)

    # Routes
    @app.route("/health")
    def health():
        """Enhanced health check endpoint with memory monitoring"""
        try:
            # Test database connection
            db.session.execute(text("SELECT 1"))

            # Memory usage monitoring (if psutil available)
            memory_info = {"available": False}
            try:
                import psutil
                process = psutil.Process(os.getpid())
                memory_mb = process.memory_info().rss / 1024 / 1024
                memory_info = {
                    "available": True,
                    "usage_mb": round(memory_mb, 2),
                    "usage_percent": round(process.memory_percent(), 2)
                }
            except ImportError:
                memory_info["message"] = "psutil not available"

            out = {
                "status": "ok",
                "db": "connected",
                "memory": memory_info,
                "timestamp": now_utc().isoformat()
            }

            # Check Redis if configured
            redis_url = os.getenv("REDIS_URL")
            if redis_url:
                try:
                    # Simple Redis connectivity check
                    try:
                        import redis
                    except ImportError:
                        out["redis"] = "redis_package_not_installed"
                        return jsonify(out), 200

                    r = redis.from_url(redis_url)
                    r.ping()
                    out["redis"] = "connected"
                except Exception as e:
                    out["redis"] = f"error: {str(e)}"
            else:
                out["redis"] = "not_configured"

            return jsonify(out), 200
        except Exception as e:
            return jsonify({
                "status": "error",
                "message": str(e),
                "timestamp": now_utc().isoformat()
            }), 500

    try:
        from prometheus_client import CollectorRegistry, Gauge, generate_latest, CONTENT_TYPE_LATEST
        registry = CollectorRegistry()
        g_uptime = Gauge('app_uptime_seconds', 'App uptime in seconds', registry=registry)
        g_updates = Gauge('updates_total', 'Total updates', registry=registry)
        g_redis = Gauge('redis_up', 'Redis up (1/0)', registry=registry)

        @app.route('/metrics')
        def metrics():
            try:
                g_uptime.set(int(time.time() - APP_START))
            except Exception:
                g_uptime.set(0)
            try:
                g_updates.set(int(Update.query.count()))
            except Exception:
                g_updates.set(0)
            # Only check Redis if configured to avoid performance issues
            redis_url = os.getenv("REDIS_URL")
            if redis_url:
                try:
                    from api.updates import is_redis_healthy
                    g_redis.set(1 if is_redis_healthy() else 0)
                except Exception:
                    g_redis.set(0)
            else:
                g_redis.set(0)  # Redis not configured
            data = generate_latest(registry)
            return (data, 200, {'Content-Type': CONTENT_TYPE_LATEST})
    except Exception:
        # If prometheus_client not available, keep the small plaintext /metrics
        @app.route('/metrics')
        def metrics_plain():
            lines = []
            try:
                uptime = time.time() - APP_START
                lines.append(f"app_uptime_seconds {int(uptime)}")
            except Exception:
                lines.append("app_uptime_seconds 0")
            try:
                total = Update.query.count()
                lines.append(f"updates_total {int(total)}")
            except Exception:
                lines.append("updates_total 0")
            # Only check Redis if configured to avoid performance issues
            redis_url = os.getenv("REDIS_URL")
            if redis_url:
                try:
                    from api.updates import is_redis_healthy
                    ok = is_redis_healthy()
                    lines.append(f"redis_up {1 if ok else 0}")
                except Exception:
                    lines.append("redis_up 0")
            else:
                lines.append("redis_up 0")  # Redis not configured
            return ("\n".join(lines), 200, {"Content-Type": "text/plain; version=0.0.4"})

    @app.route('/health/alert', methods=['POST'])
    def health_alert():
        """Trigger a POST to a configured alert webhook with current health status.

        Useful for manual or automated alerting during deployment checks.
        Configure `HEALTH_ALERT_URL` in the environment to enable.
        """
        url = os.getenv('HEALTH_ALERT_URL')
        if not url:
            return jsonify({'error': 'no_webhook_configured'}), 400
        try:
            import requests
            # Reuse /health to get current status
            with app.test_client() as c:
                resp = c.get('/health')
                payload = resp.get_json()
            r = requests.post(url, json=payload, timeout=5)
            return jsonify({'status': 'sent', 'response_code': r.status_code}), 200
        except Exception as e:
            return jsonify({'error': str(e)}), 500

    @app.route("/lessons_learned/view/<int:lesson_id>")
    @login_required
    def view_lesson_learned(lesson_id):
        lesson = LessonLearned.query.get(lesson_id)
        if not lesson:
            flash("Lesson Learned not found.")
            return redirect(url_for("list_lessons_learned"))
        return render_template("view_lesson_learned.html", lesson=lesson)

    @app.route("/search")
    def search():
        query = request.args.get("q", "").strip()
        results = []

        # Get filter parameters
        category = request.args.get("category", "")
        process = request.args.get("process", "")
        department = request.args.get("department", "")
        date_range = request.args.get("date_range", "")

        # Prepare filters for template
        filters = {
            "category": category,
            "process": process,
            "department": department,
            "date_range": date_range
        }

        # Available options for filters
        available_processes = ["ABC", "XYZ", "AB"]
        available_departments = ["ABC", "XYZ", "AB"]  # Fixed to match process options

        if query:
            # Case-insensitive search
            query_filter = f"%{query}%"

            # Search Updates (if no category filter or category is 'updates')
            if not category or category == "updates":
                updates_query = Update.query.filter(
                    or_(
                        Update.message.ilike(query_filter),
                        Update.name.ilike(query_filter),
                        Update.process.ilike(query_filter)
                    )
                )

                # Apply process filter
                if process:
                    updates_query = updates_query.filter(Update.process.ilike(f"%{process}%"))

                updates_rows = updates_query.order_by(Update.timestamp.desc()).all()

                for upd in updates_rows:
                    results.append({
                        "id": upd.id,
                        "title": f"{upd.process} - {upd.name}",
                        "content": upd.message[:200] + ("..." if len(upd.message) > 200 else ""),
                        "type": "update",
                        "url": url_for("view_update", update_id=upd.id),
                        "author": upd.name,
                        "created_at": upd.timestamp,
                        "process": upd.process
                    })

            # Search SOP Summaries (if no category filter or category is 'sops')
            if not category or category == "sops":
                sops_query = SOPSummary.query.filter(
                    or_(
                        SOPSummary.title.ilike(query_filter),
                        SOPSummary.summary_text.ilike(query_filter)
                    )
                )

                # Apply department filter
                if department:
                    sops_query = sops_query.filter(SOPSummary.department.ilike(f"%{department}%"))

                sops_rows = sops_query.order_by(SOPSummary.created_at.desc()).all()

                for sop in sops_rows:
                    results.append({
                        "id": sop.id,
                        "title": sop.title,
                        "content": sop.summary_text[:200] + ("..." if len(sop.summary_text) > 200 else ""),
                        "type": "sop",
                        "url": url_for("view_sop_summary", summary_id=sop.id),
                        "created_at": sop.created_at,
                        "tags": sop.tags or []
                    })

            # Search Lessons Learned (if no category filter or category is 'lessons')
            if not category or category == "lessons":
                lessons_query = LessonLearned.query.filter(
                    or_(
                        LessonLearned.title.ilike(query_filter),
                        LessonLearned.content.ilike(query_filter),
                        LessonLearned.summary.ilike(query_filter)
                    )
                )

                # Apply department filter
                if department:
                    lessons_query = lessons_query.filter(LessonLearned.department.ilike(f"%{department}%"))

                lessons_rows = lessons_query.order_by(LessonLearned.created_at.desc()).all()

                for lesson in lessons_rows:
                    results.append({
                        "id": lesson.id,
                        "title": lesson.title,
                        "content": (lesson.summary or lesson.content or "")[:200] + ("..." if len(lesson.summary or lesson.content or "") > 200 else ""),
                        "type": "lesson",
                        "url": url_for("view_lesson_learned", lesson_id=lesson.id),
                        "author": lesson.author,
                        "created_at": lesson.created_at,
                        "tags": lesson.tags or []
                    })

        return render_template("search_results.html",
                             query=query,
                             results=results,
                             filters=filters,
                             available_processes=available_processes,
                             available_departments=available_departments)



    @app.route("/")
    def home():
        try:
            summaries = SOPSummary.query.order_by(SOPSummary.created_at.desc()).all()
            lessons = LessonLearned.query.order_by(LessonLearned.created_at.desc()).all()
            
            # Get latest updates for the home page - simplified version
            latest_updates = Update.query.order_by(Update.timestamp.desc()).limit(5).all()
            updates_data = []
            
            for update in latest_updates:
                update_dict = update.to_dict()
                update_dict['read_count'] = 0  # Simplified for now
                update_dict['is_new'] = False  # Simplified for now
                updates_data.append(update_dict)
            
            return render_template("home.html", app_name=app.config["APP_NAME"],
                                 summaries=summaries, lessons=lessons, updates=updates_data,
                                 excel_export_available=EXCEL_EXPORT_AVAILABLE)
        except Exception as e:
            # Return a basic template without updates if there's an error
            return render_template("home.html", app_name=app.config["APP_NAME"],
                                 summaries=[], lessons=[], updates=[],
                                 excel_export_available=EXCEL_EXPORT_AVAILABLE)

    @app.route("/updates")
    def show_updates():
        # Get filter parameters from query string
        selected_process = request.args.get("process", "")
        selected_department = request.args.get("department", "")
        sort = request.args.get("sort", "newest")
        
        # Base query
        base_query = (
            db.session.query(Update, func.count(ReadLog.id).label('read_count'))
            .outerjoin(ReadLog, ReadLog.update_id == Update.id)
            .group_by(Update.id)
        )
        
        # Apply process filter if specified
        if selected_process:
            base_query = base_query.filter(Update.process == selected_process)
        
        # Apply sorting
        if sort == "oldest":
            base_query = base_query.order_by(Update.timestamp.asc())
        elif sort == "process":
            base_query = base_query.order_by(Update.process.asc(), Update.timestamp.desc())
        elif sort == "author":
            base_query = base_query.order_by(Update.name.asc(), Update.timestamp.desc())
        else:  # newest (default)
            base_query = base_query.order_by(Update.timestamp.desc())
        
        rows = base_query.all()

        updates = []
        current_time = now_utc()
        for upd, count in rows:
            d = upd.to_dict()
            d['read_count'] = count

            # determine if it's within last 24 hours
            d['is_new'] = is_within_hours(upd.timestamp, 24, current_time)

            # Add the original datetime object for isoformat() in template
            d['timestamp_obj'] = upd.timestamp

            updates.append(d)

        # Get additional data for template
        all_updates = Update.query.all()
        unique_authors = list(set([upd.name for upd in all_updates if upd.name]))
        processes = list(set([upd.process for upd in all_updates if upd.process]))
        
        # Calculate updates this week
        updates_this_week = 0
        for upd in all_updates:
            if upd.timestamp and is_within_hours(upd.timestamp, 24 * 7, current_time):
                updates_this_week += 1
        
        # Get unique departments (consistent with other forms)
        departments = ["ABC", "XYZ", "AB"]
        
        return render_template("show.html", 
                             app_name=app.config["APP_NAME"], 
                             updates=updates,
                             unique_authors=unique_authors,
                             processes=processes,
                             departments=departments,
                             updates_this_week=updates_this_week,
                             selected_process=selected_process,
                             selected_department=selected_department,
                             sort=sort)

    @app.route("/post", methods=["GET", "POST"])
    @writer_required
    def post_update():
        processes = ["ABC", "XYZ", "AB"]

        if request.method == "POST":
            message = request.form.get("message", "").strip()
            selected_process = request.form.get("process")
            name = inject_current_user()["current_user"].display_name

            if not message or not selected_process:
                flash("‚ö†Ô∏è Message and process are required.")
                return redirect(url_for("post_update"))

            new_update = Update(
                id=uuid.uuid4().hex,
                name=name,
                process=selected_process,
                message=message,
                timestamp=now_utc(),
            )
            try:
                db.session.add(new_update)
                db.session.commit()
                flash("‚úÖ Update posted.")

                # Log activity
                log_activity('created', 'update', new_update.id, f"Update: {message[:50]}...")

                # Broadcast the new update via Socket.IO
                try:
                    if os.getenv("FLASK_ENV") == "development":
                        logger.info(f"üîÑ Broadcasting new update via Socket.IO - ID: {new_update.id}")
                        print(f"üîÑ Broadcasting new update via Socket.IO - ID: {new_update.id}")
                    from api.socketio import broadcast_update
                    update_data = {
                        'id': new_update.id,
                        'name': new_update.name,
                        'process': new_update.process,
                        'message': new_update.message,
                        'timestamp': new_update.timestamp.isoformat()
                    }
                    if os.getenv("FLASK_ENV") == "development":
                        logger.info(f"üì¶ Update data prepared: {update_data}")
                        print(f"üì¶ Update data prepared for broadcasting")
                    broadcast_update(update_data, selected_process)
                    if os.getenv("FLASK_ENV") == "development":
                        logger.info(f"‚úÖ Broadcast function called successfully for update {new_update.id}")
                        print(f"‚úÖ Broadcast function called successfully for update {new_update.id}")
                except Exception as e:
                    # Socket.IO broadcasting failure shouldn't break the posting
                    logger.error(f"‚ùå Socket.IO broadcast failed: {e}")
                    if os.getenv("FLASK_ENV") == "development":
                        print(f"‚ùå Socket.IO broadcast failed: {e}")

            except Exception:
                db.session.rollback()
                flash("‚ö†Ô∏è Failed to post update.")
            return redirect(url_for("show_updates"))

        return render_template("post.html", app_name=app.config["APP_NAME"], processes=processes)

    @app.route("/edit/<update_id>", methods=["GET", "POST"])
    @writer_required
    def edit_update(update_id):
        update = Update.query.get(update_id)
        current = inject_current_user()["current_user"]
        if not update or update.name != current.display_name:
            flash("üö´ Unauthorized or not found.")
            return redirect(url_for("show_updates"))

        if request.method == "POST":
            new_message = request.form.get("message", "").strip()
            if not new_message:
                flash("‚ö†Ô∏è Message cannot be empty.")
                return redirect(url_for("edit_update", update_id=update_id))
            update.message = new_message
            update.timestamp = now_utc()
            try:
                db.session.commit()
                flash("‚úèÔ∏è Update edited successfully.")

                # Log activity
                log_activity('edited', 'update', update.id, f"Update: {new_message[:50]}...")

            except Exception:
                db.session.rollback()
                flash("‚ö†Ô∏è Failed to edit update.")
            return redirect(url_for("show_updates"))

        return render_template("edit.html", app_name=app.config["APP_NAME"], update=update)

    @app.route("/view/<update_id>")
    def view_update(update_id):
        """View a specific update"""
        update = Update.query.get(update_id)
        if not update:
            flash("üö´ Update not found.")
            return redirect(url_for("show_updates"))
        
        # Get read count for this update
        read_count = db.session.query(func.count(ReadLog.id)).filter(
            ReadLog.update_id == update_id
        ).scalar()
        
        # Check if current user has read this update
        is_read = False
        if session.get("user_id"):
            read_log = ReadLog.query.filter_by(
                update_id=update_id,
                user_id=session["user_id"]
            ).first()
            is_read = read_log is not None
        
        return render_template("view_update.html", 
                             app_name=app.config["APP_NAME"], 
                             update=update, 
                             read_count=read_count,
                             is_read=is_read)

    @app.route("/delete/<update_id>", methods=["POST"])
    @login_required
    def delete_update(update_id):
        update = Update.query.get(update_id)
        current = inject_current_user()["current_user"]
        
        # Prepare response data
        response = {"success": False, "message": ""}
        
        if not update:
            response["message"] = "‚ö†Ô∏è Update not found."
            status_code = 404
        elif update.name.strip().lower() != current.display_name.strip().lower():
            response["message"] = "üö´ Not authorized to delete."
            status_code = 403
        else:
            # Capture details before deletion
            entity_title = f"Update: {update.message[:50]}..."

            try:
                # Archive the update before deletion
                if archive_update(update):
                    db.session.delete(update)
                    db.session.commit()
                    response["success"] = True
                    response["message"] = "‚úÖ Update deleted and archived."
                    status_code = 200

                    # Log activity after successful deletion
                    log_activity('deleted', 'update', update_id, entity_title)
                else:
                    response["message"] = "‚ö†Ô∏è Failed to archive update. Deletion cancelled for safety."
                    status_code = 500

            except Exception as e:
                db.session.rollback()
                response["message"] = "‚ùå Deletion failed."
                status_code = 500
                logger.error(f"Failed to delete update: {e}")

        # Handle both AJAX and form submissions
        is_ajax = request.headers.get('X-Requested-With') == 'XMLHttpRequest'
        if is_ajax:
            return jsonify(response), status_code
        else:
            flash(response["message"])
            return redirect(url_for("show_updates"))
            
    @app.route("/register", methods=["GET", "POST"])
    def register():
        if request.method == "POST":
            display_name = request.form["display_name"].strip()
            username = request.form["username"].strip().replace(" ", "_").lower()
            password = request.form["password"]

            if not re.match("^[A-Za-z0-9_]+$", username):
                flash("üö´ Username can only contain letters, numbers, and underscores.")
                return redirect(url_for("register"))

            if not username or not display_name or not password:
                flash("‚ö†Ô∏è All fields required.")
                return redirect(url_for("register"))

            if User.query.filter_by(username=username).first():
                flash("üö´ Username taken.")
                return redirect(url_for("register"))

            new_user = User(username=username, display_name=display_name)
            new_user.set_password(password)
            db.session.add(new_user)
            db.session.commit()

            flash("‚úÖ Registered! Please log in.")
            return redirect(url_for("login"))

        return render_template("register.html", app_name=app.config["APP_NAME"])

    @app.route("/login", methods=["GET", "POST"])
    def login():
        if request.method == "POST":
            username = request.form["username"].strip().replace(" ", "_").lower()
            password = request.form["password"]
            user = User.query.filter_by(username=username).first()
            if user and user.check_password(password):
                session["user_id"] = user.id
                flash(f"üëã Welcome back, {user.display_name}!")

                # Handle redirect logic
                next_page = request.form.get('next') or request.args.get('next')

                # If user came from home page login button, redirect to home
                if next_page == 'home':
                    return redirect(url_for("home"))
                # If there's a next page specified, redirect there
                elif next_page:
                    # Check if it's a full URL (from role decorators)
                    if next_page.startswith('http') or next_page.startswith('/'):
                        # Validate that it's a safe redirect within our app
                        from urllib.parse import urlparse
                        parsed = urlparse(next_page)
                        if not parsed.netloc or parsed.netloc == request.host:
                            return redirect(next_page)

                    # Map of valid endpoints to their URL functions
                    valid_endpoints = {
                        'show_updates': 'show_updates',
                        'post_update': 'post_update',
                        'list_sop_summaries': 'list_sop_summaries',
                        'list_lessons_learned': 'list_lessons_learned',
                        'search': 'search',
                        'add_sop_summary': 'add_sop_summary',
                        'add_lesson_learned': 'add_lesson_learned',
                        'export_readlogs': 'export_readlogs'
                    }

                    # Handle search result redirects for SOPs and Lessons
                    if next_page == 'view_sop_summary':
                        return redirect(url_for('list_sop_summaries'))
                    elif next_page == 'view_lesson_learned':
                        return redirect(url_for('list_lessons_learned'))
                    elif next_page in valid_endpoints:
                        return redirect(url_for(valid_endpoints[next_page]))

                # Default fallback to home page instead of show_updates
                return redirect(url_for("home"))

            flash("üö´ Invalid credentials.")
            return redirect(url_for("login"))

        # For GET requests, preserve the next parameter
        next_page = request.args.get('next')
        return render_template("login.html", app_name=app.config["APP_NAME"], next_page=next_page)

    @app.route("/logout")
    def logout():
        session.pop("user_id", None)
        flash("üëã You‚Äôve been logged out.")
        return redirect(url_for("home"))

    @app.route("/api/latest-update-time")
    def api_latest_update_time():
        """API endpoint to get the timestamp of the most recent update"""
        try:
            latest_update = Update.query.order_by(Update.timestamp.desc()).first()
            if latest_update:
                # Ensure timezone is properly handled
                timestamp = ensure_timezone(latest_update.timestamp, UTC)

                return jsonify({
                    "latest_timestamp": timestamp.isoformat(),
                    "success": True
                })
            else:
                return jsonify({
                    "latest_timestamp": None,
                    "success": True
                })
        except Exception as e:
            logger.error(f"Error getting latest update time: {e}")
            return jsonify({
                "latest_timestamp": None,
                "success": False,
                "error": str(e)
            }), 500
    
    # New routes for SOP Summaries
    @app.route("/sop_summaries")
    @login_required
    def list_sop_summaries():
        sops = SOPSummary.query.order_by(SOPSummary.created_at.desc()).all()
        return render_template("sop_summaries.html", sops=sops)

    @app.route("/sop_summaries/add", methods=["GET", "POST"])
    @writer_required
    def add_sop_summary():
        if request.method == "POST":
            title = request.form.get("title", "").strip()
            summary_text = request.form.get("summary_text", "").strip()
            department = request.form.get("department", "").strip()
            tags = request.form.get("tags", "").strip()

            if not title or not summary_text:
                flash("Title and Summary are required.")
                return redirect(url_for("add_sop_summary"))

            tags_list = [tag.strip() for tag in tags.split(",")] if tags else []

            sop = SOPSummary(
                title=title,
                summary_text=summary_text,
                department=department or None,
                tags=tags_list or None,
            )
            try:
                db.session.add(sop)
                db.session.commit()
                flash("SOP Summary added successfully.")

                # Log activity
                log_activity('created', 'sop', sop.id, title)

                # Broadcast notification for new SOP
                try:
                    from api.socketio import broadcast_notification
                    broadcast_notification({
                        'type': 'new_sop',
                        'title': 'New SOP Added',
                        'message': f'**NEW SOP:** {title}',
                        'timestamp': now_utc().isoformat()
                    })
                except Exception as e:
                    if os.getenv("FLASK_ENV") == "development":
                        print(f"Socket.IO broadcast failed: {e}")

                return redirect(url_for("list_sop_summaries"))
            except Exception as e:
                db.session.rollback()
                flash("Failed to add SOP Summary.")
                logger.error(f"Failed to add SOP Summary: {e}")
                return redirect(url_for("add_sop_summary"))

        return render_template("add_sop_summary.html")

    @app.route("/sop_summaries/edit/<int:sop_id>", methods=["GET", "POST"])
    @writer_required
    def edit_sop_summary(sop_id):
        sop = SOPSummary.query.get(sop_id)
        if not sop:
            flash("SOP Summary not found.")
            return redirect(url_for("list_sop_summaries"))

        if request.method == "POST":
            title = request.form.get("title", "").strip()
            summary_text = request.form.get("summary_text", "").strip()
            department = request.form.get("department", "").strip()
            tags = request.form.get("tags", "").strip()

            if not title or not summary_text:
                flash("Title and Summary are required.")
                return redirect(url_for("edit_sop_summary", sop_id=sop_id))

            tags_list = [tag.strip() for tag in tags.split(",")] if tags else []

            sop.title = title
            sop.summary_text = summary_text
            sop.department = department or None
            sop.tags = tags_list or None
            try:
                db.session.commit()
                flash("‚úÖ SOP Summary updated successfully.")

                # Log activity
                log_activity('edited', 'sop', sop.id, title)

            except Exception as e:
                db.session.rollback()
                flash("‚ùå Failed to update SOP Summary.")
                logger.error(f"Failed to update SOP Summary: {e}")

            # Check if user came from view page or list page
            referrer = request.form.get('referrer') or request.referrer
            if referrer and 'sop_summaries/' in referrer and str(sop_id) in referrer:
                return redirect(url_for("view_sop_summary", summary_id=sop_id))
            else:
                return redirect(url_for("list_sop_summaries"))

        return render_template("edit_sop_summary.html", sop=sop)

    @app.route("/sop_summaries/delete/<int:sop_id>", methods=["POST"])
    @delete_required
    def delete_sop_summary(sop_id):
        sop = SOPSummary.query.get(sop_id)
        if not sop:
            flash("‚ö†Ô∏è SOP Summary not found.")
            return redirect(url_for("list_sop_summaries"))

        # Capture details before deletion
        entity_title = sop.title

        try:
            # Archive the SOP before deletion
            if archive_sop(sop):
                db.session.delete(sop)
                db.session.commit()
                flash("‚úÖ SOP Summary deleted and archived.")

                # Log activity after successful deletion
                log_activity('deleted', 'sop', sop_id, entity_title)
            else:
                flash("‚ö†Ô∏è Failed to archive SOP. Deletion cancelled for safety.")

        except Exception as e:
            db.session.rollback()
            flash("‚ùå Failed to delete SOP Summary.")
            logger.error(f"Failed to delete SOP Summary: {e}")

        # Always redirect to list page after deletion since the item no longer exists
        return redirect(url_for("list_sop_summaries"))

    # New routes for Lessons Learned
    @app.route("/lessons_learned")
    @login_required
    def list_lessons_learned():
        lessons = LessonLearned.query.order_by(LessonLearned.created_at.desc()).all()
        return render_template("lessons_learned.html", lessons=lessons)

    @app.route("/lessons_learned/add", methods=["GET", "POST"])
    @writer_required
    def add_lesson_learned():
        if request.method == "POST":
            title = request.form.get("title", "").strip()
            content = request.form.get("content", "").strip()
            summary = request.form.get("summary", "").strip()
            author = request.form.get("author", "").strip()
            department = request.form.get("department", "").strip()
            tags = request.form.get("tags", "").strip()

            if not title or not content:
                flash("Title and Content are required.")
                return redirect(url_for("add_lesson_learned"))

            tags_list = [tag.strip() for tag in tags.split(",")] if tags else []

            lesson = LessonLearned(
                title=title,
                content=content,
                summary=summary or None,
                author=author or None,
                department=department or None,
                tags=tags_list or None,
            )
            try:
                db.session.add(lesson)
                db.session.commit()
                flash("Lesson Learned added successfully.")

                # Log activity
                log_activity('created', 'lesson', lesson.id, title)

                # Broadcast notification for new Lesson Learned
                try:
                    from api.socketio import broadcast_notification
                    broadcast_notification({
                        'type': 'new_lesson',
                        'title': 'New Lesson Learned',
                        'message': f'**NEW LESSON:** {title}',
                        'timestamp': now_utc().isoformat()
                    })
                except Exception as e:
                    if os.getenv("FLASK_ENV") == "development":
                        print(f"Socket.IO broadcast failed: {e}")

                return redirect(url_for("list_lessons_learned"))
            except Exception as e:
                db.session.rollback()
                flash("Failed to add Lesson Learned.")
                logger.error(f"Failed to add Lesson Learned: {e}")
                return redirect(url_for("add_lesson_learned"))

        return render_template("add_lesson_learned.html")

    @app.route("/lessons_learned/edit/<int:lesson_id>", methods=["GET", "POST"])
    @writer_required
    def edit_lesson_learned(lesson_id):
        lesson = LessonLearned.query.get(lesson_id)
        if not lesson:
            flash("Lesson Learned not found.")
            return redirect(url_for("list_lessons_learned"))

        if request.method == "POST":
            title = request.form.get("title", "").strip()
            content = request.form.get("content", "").strip()
            summary = request.form.get("summary", "").strip()
            author = request.form.get("author", "").strip()
            department = request.form.get("department", "").strip()
            tags = request.form.get("tags", "").strip()

            if not title or not content:
                flash("Title and Content are required.")
                return redirect(url_for("edit_lesson_learned", lesson_id=lesson_id))

            tags_list = [tag.strip() for tag in tags.split(",")] if tags else []

            lesson.title = title
            lesson.content = content
            lesson.summary = summary or None
            lesson.author = author or None
            lesson.department = department or None
            lesson.tags = tags_list or None

            try:
                db.session.commit()
                flash("‚úÖ Lesson Learned updated successfully.")

                # Log activity
                log_activity('edited', 'lesson', lesson.id, title)

            except Exception as e:
                db.session.rollback()
                flash("‚ùå Failed to update Lesson Learned.")
                logger.error(f"Failed to update Lesson Learned: {e}")

            # Check if user came from view page or list page
            referrer = request.form.get('referrer') or request.referrer
            if referrer and 'lessons_learned/view/' in referrer and str(lesson_id) in referrer:
                return redirect(url_for("view_lesson_learned", lesson_id=lesson_id))
            else:
                return redirect(url_for("list_lessons_learned"))

        return render_template("edit_lesson_learned.html", lesson=lesson)

    @app.route("/lessons_learned/delete/<int:lesson_id>", methods=["POST"])
    @delete_required
    def delete_lesson_learned(lesson_id):
        lesson = LessonLearned.query.get(lesson_id)
        if not lesson:
            flash("Lesson Learned not found.")
            return redirect(url_for("list_lessons_learned"))

        # Capture details before deletion
        entity_title = lesson.title

        try:
            # Archive the lesson before deletion
            if archive_lesson(lesson):
                db.session.delete(lesson)
                db.session.commit()
                flash("‚úÖ Lesson Learned deleted and archived.")

                # Log activity after successful deletion
                log_activity('deleted', 'lesson', lesson_id, entity_title)
            else:
                flash("‚ö†Ô∏è Failed to archive lesson. Deletion cancelled for safety.")

        except Exception as e:
            db.session.rollback()
            flash("‚ùå Failed to delete Lesson Learned.")

        # Always redirect to list page after deletion since the item no longer exists
        return redirect(url_for("list_lessons_learned"))
    

        
    @app.route("/sop_summaries/<int:summary_id>")
    @login_required
    def view_sop_summary(summary_id):
        summary = SOPSummary.query.get(summary_id)
        if not summary:
            flash("\u26a0\ufe0f SOP Summary not found.")
            return redirect(url_for("list_sop_summaries"))

        return render_template(
            "view_sop_summary.html",
            summary=summary,
            app_name=current_app.config["APP_NAME"]
        )



    @app.route("/api/recent-updates")
    def recent_updates():
        """Get updates from the past 24 hours for the bell icon banner."""
        try:
            # Calculate 24 hours ago
            twenty_four_hours_ago = get_hours_ago(24)

            # Query for recent updates
            recent_updates = Update.query.filter(
                Update.timestamp >= twenty_four_hours_ago
            ).order_by(Update.timestamp.desc()).limit(10).all()

            updates_data = []
            for update in recent_updates:
                # Ensure timezone is properly handled
                timestamp = ensure_timezone(update.timestamp, UTC)

                updates_data.append({
                    "id": update.id,
                    "name": update.name,
                    "process": update.process,
                    "message": update.message,
                    "timestamp": timestamp.isoformat()
                })

            return jsonify({
                "success": True,
                "updates": updates_data
            })
        except Exception as e:
            return jsonify({
                "success": False,
                "error": str(e)
            }), 500

    @app.route("/export-readlogs")
    @export_required
    def export_readlogs():
        """Export read logs to Excel file with comprehensive analytics."""
        # Check if Excel export dependencies are available
        if not EXCEL_EXPORT_AVAILABLE:
            flash("‚ùå Excel export feature is not available. Please install pandas and openpyxl.", "error")
            return redirect(url_for('home'))

        # Check if this is a download request
        download = request.args.get('download', 'false').lower() == 'true'

        if not download:
            try:
                # Get summary stats for the export page
                total_logs = ReadLog.query.count()
                unique_readers = db.session.query(func.count(func.distinct(ReadLog.user_id))).scalar()
                date_range = db.session.query(
                    func.min(ReadLog.timestamp).label('start'),
                    func.max(ReadLog.timestamp).label('end')
                ).first()

                return render_template('export_readlogs.html',
                                 app_name=app.config["APP_NAME"],
                                 total_logs=total_logs,
                                 unique_readers=unique_readers,
                                 date_range=date_range)
            except Exception as e:
                flash(f"‚ùå Error getting export statistics: {str(e)}", "error")
                return redirect(url_for('home'))

        # If download=true, proceed with file generation and download
        try:
            # Query all read logs with related data - using explicit aliases to avoid parameter conflicts
            from sqlalchemy.orm import aliased
            update_alias = aliased(Update)
            user_alias = aliased(User)

            read_logs_query = db.session.query(
                ReadLog.id,
                ReadLog.timestamp,
                ReadLog.guest_name,
                ReadLog.ip_address,
                ReadLog.user_agent,
                update_alias.id.label('update_id'),
                update_alias.message.label('update_message'),
                update_alias.name.label('update_author'),
                update_alias.process.label('update_process'),
                update_alias.timestamp.label('update_created'),
                user_alias.display_name.label('reader_name'),
                user_alias.username.label('reader_username')
            ).outerjoin(
                update_alias, ReadLog.update_id == update_alias.id
            ).outerjoin(
                user_alias, ReadLog.user_id == user_alias.id
            ).order_by(ReadLog.timestamp.desc())

            # Execute query and get results
            results = read_logs_query.all()

            # Prepare data for Excel
            data = []
            for row in results:
                # Determine reader name (user or guest)
                reader_name = row.reader_name if row.reader_name else (row.guest_name or "Anonymous")
                reader_type = "Registered User" if row.reader_name else "Guest"

                # Format timestamps
                read_time = row.timestamp.strftime('%Y-%m-%d %H:%M:%S') if row.timestamp else ""
                update_created_time = row.update_created.strftime('%Y-%m-%d %H:%M:%S') if row.update_created else ""

                # Truncate long messages for readability
                update_message = (row.update_message[:100] + "...") if row.update_message and len(row.update_message) > 100 else (row.update_message or "")

                data.append({
                    'Read Log ID': row.id,
                    'Reader Name': reader_name,
                    'Reader Type': reader_type,
                    'Reader Username': row.reader_username or "N/A",
                    'Read Timestamp': read_time,
                    'IP Address': row.ip_address or "N/A",
                    'Browser User-Agent': row.user_agent or "N/A",
                    'Update ID': row.update_id or "N/A",
                    'Update Message': update_message,
                    'Update Author': row.update_author or "N/A",
                    'Update Process': row.update_process or "N/A",
                    'Update Created': update_created_time,
                })

            # Create DataFrame
            df = pd.DataFrame(data)

            # Create summary statistics
            summary_data = []

            # Total reads
            total_reads = len(df)
            summary_data.append({'Metric': 'Total Reads', 'Value': total_reads})

            # Unique readers
            unique_readers = df['Reader Name'].nunique()
            summary_data.append({'Metric': 'Unique Readers', 'Value': unique_readers})

            # Registered vs Guest reads
            registered_reads = len(df[df['Reader Type'] == 'Registered User'])
            guest_reads = len(df[df['Reader Type'] == 'Guest'])
            summary_data.append({'Metric': 'Registered User Reads', 'Value': registered_reads})
            summary_data.append({'Metric': 'Guest Reads', 'Value': guest_reads})

            # Most active readers (top 10)
            top_readers = df['Reader Name'].value_counts().head(10)

            # Most read updates (top 10)
            most_read_updates = df.groupby(['Update ID', 'Update Message', 'Update Author']).size().reset_index(name='Read Count').sort_values('Read Count', ascending=False).head(10)

            # Create Excel file in memory
            output = BytesIO()

            # Query activity logs - using explicit aliases to avoid parameter conflicts
            activity_logs_query = db.session.query(
                ActivityLog.id,
                ActivityLog.action,
                ActivityLog.entity_type,
                ActivityLog.entity_id,
                ActivityLog.entity_title,
                ActivityLog.timestamp,
                ActivityLog.ip_address,
                ActivityLog.user_agent,
                ActivityLog.details,
                user_alias.display_name.label('user_name'),
                user_alias.username.label('username')
            ).outerjoin(
                user_alias, ActivityLog.user_id == user_alias.id
            ).order_by(ActivityLog.timestamp.desc())

            activity_results = activity_logs_query.all()

            # Prepare activity logs data
            activity_data = []
            for row in activity_results:
                user_name = row.user_name if row.user_name else "System"
                # Convert UTC timestamp to IST for proper display
                if row.timestamp:
                    ist_timestamp = to_ist(row.timestamp)
                    activity_time = ist_timestamp.strftime('%Y-%m-%d %H:%M:%S')
                else:
                    activity_time = ""

                activity_data.append({
                    'Activity ID': row.id,
                    'User Name': user_name,
                    'Username': row.username or "N/A",
                    'Action': row.action.title(),
                    'Entity Type': row.entity_type.upper(),
                    'Entity ID': row.entity_id,
                    'Entity Title': row.entity_title or "N/A",
                    'Timestamp': activity_time,
                    'IP Address': row.ip_address or "N/A",
                    'Browser User-Agent': row.user_agent or "N/A",
                    'Details': row.details or "N/A"
                })

            activity_df = pd.DataFrame(activity_data)

            # Query registered users for authority tracking - using explicit aliases to avoid parameter conflicts
            users_query = db.session.query(
                user_alias.id,
                user_alias.username,
                user_alias.display_name,
                user_alias.email,
                user_alias.role
            ).order_by(user_alias.id)

            users_results = users_query.all()
            users_data = []
            for idx, user in enumerate(users_results, 1):
                users_data.append({
                    'Serial #': idx,
                    'User ID': user.id,
                    'Username': user.username,
                    'Display Name': user.display_name,
                    'Email': user.email or "N/A",
                    'Role': user.role.title()
                })

            users_df = pd.DataFrame(users_data)

            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                # Main data sheet
                df.to_excel(writer, sheet_name='Read Logs', index=False)

                # Summary sheet
                summary_df = pd.DataFrame(summary_data)
                summary_df.to_excel(writer, sheet_name='Summary', index=False)

                # Activity Logs sheet
                activity_df.to_excel(writer, sheet_name='Activity Logs', index=False)

                # Registered Users sheet
                users_df.to_excel(writer, sheet_name='Registered Users', index=False)

                # Top readers sheet
                top_readers_df = pd.DataFrame({
                    'Reader Name': top_readers.index,
                    'Total Reads': top_readers.values
                })
                top_readers_df.to_excel(writer, sheet_name='Top Readers', index=False)

                # Most read updates sheet
                most_read_updates.to_excel(writer, sheet_name='Most Read Updates', index=False)

                # Process-wise analytics
                if not df.empty and 'Update Process' in df.columns:
                    process_stats = df.groupby('Update Process').agg({
                        'Read Log ID': 'count',
                        'Reader Name': 'nunique'
                    }).rename(columns={
                        'Read Log ID': 'Total Reads',
                        'Reader Name': 'Unique Readers'
                    }).reset_index()
                    process_stats.to_excel(writer, sheet_name='Process Analytics', index=False)

                # Format the Excel sheets
                for sheet_name in writer.sheets:
                    worksheet = writer.sheets[sheet_name]

                    # Auto-adjust column widths
                    for column in worksheet.columns:
                        max_length = 0
                        column_letter = column[0].column_letter

                        for cell in column:
                            try:
                                if len(str(cell.value)) > max_length:
                                    max_length = len(str(cell.value))
                            except:
                                pass

                        adjusted_width = min(max_length + 2, 50)  # Cap at 50 characters
                        worksheet.column_dimensions[column_letter].width = adjusted_width

            output.seek(0)

            # Generate filename with timestamp
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f'readlogs_export_{timestamp}.xlsx'

            return send_file(
                output,
                as_attachment=True,
                download_name=filename,
                mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
            )

        except Exception as e:
            # Log the error
            current_app.logger.error(f"Error exporting read logs: {str(e)}")

            # Return error page or redirect with flash message
            flash(f"‚ùå Error exporting read logs: {str(e)}", "error")
            return redirect(url_for('home'))

    @app.route("/reset-activity-logs", methods=["POST"])
    @admin_required
    def reset_activity_logs():
        """Reset (delete all) activity logs with admin password verification."""
        try:
            # Get the admin password from the form
            admin_password = request.form.get('admin_password', '').strip()

            if not admin_password:
                flash("‚ùå Admin password is required to reset activity logs.", "error")
                return redirect(url_for('export_readlogs'))

            # Get the current admin user
            admin_user_id = session.get("user_id")
            if not admin_user_id:
                flash("‚ùå Authentication error. Please log in again.", "error")
                return redirect(url_for('login'))

            admin_user = User.query.get(admin_user_id)
            if not admin_user or admin_user.role != 'admin':
                flash("‚ùå Admin access required.", "error")
                return redirect(url_for('home'))

            # Verify the admin password
            if not admin_user.check_password(admin_password):
                flash("‚ùå Incorrect admin password. Activity logs were not reset.", "error")
                return redirect(url_for('export_readlogs'))

            # Count current activity logs before deletion
            activity_count = ActivityLog.query.count()

            # Delete all activity logs
            ActivityLog.query.delete()
            db.session.commit()

            flash(f"‚úÖ Successfully reset activity logs. {activity_count} records were deleted.", "success")

            # Log this action (create a new activity log entry for the reset)
            log_activity('reset', 'activity_logs', 'all', f"Reset all activity logs ({activity_count} records)",
                        details=f"Admin {admin_user.display_name} reset all activity logs")

        except Exception as e:
            db.session.rollback()
            flash(f"‚ùå Error resetting activity logs: {str(e)}", "error")

        return redirect(url_for('export_readlogs'))

    @app.route("/backup")
    @admin_required
    def backup_page():
        """Display backup management page."""
        try:
            from backup_system import DatabaseBackupSystem
            backup_system = DatabaseBackupSystem()
            backups = backup_system.list_backups()
            return render_template('backup.html',
                                 app_name=app.config["APP_NAME"],
                                 backups=backups)
        except Exception as e:
            flash(f"‚ùå Error loading backup page: {str(e)}", "error")
            return redirect(url_for('home'))

    @app.route("/backup/create", methods=["POST"])
    @admin_required
    def create_backup():
        """Create a new database backup."""
        try:
            from backup_system import DatabaseBackupSystem
            backup_system = DatabaseBackupSystem()

            backup_type = request.form.get('backup_type', 'manual')
            backup_path = backup_system.create_backup(backup_type)

            if backup_path:
                flash(f"‚úÖ Backup created successfully: {backup_path.name}", "success")
            else:
                flash("‚ùå Failed to create backup. Check logs for details.", "error")

        except Exception as e:
            flash(f"‚ùå Error creating backup: {str(e)}", "error")

        return redirect(url_for('backup_page'))

    @app.route("/backup/restore", methods=["POST"])
    @admin_required
    def restore_backup():
        """Restore database from backup with improved error handling."""
        import threading
        import time

        try:
            backup_file = request.form.get('backup_file')
            if not backup_file:
                flash("‚ùå Please select a backup file to restore.", "error")
                return redirect(url_for('backup_page'))

            backup_path = Path("backups") / backup_file

            # Check if backup file exists
            if not backup_path.exists():
                flash(f"‚ùå Backup file not found: {backup_file}", "error")
                return redirect(url_for('backup_page'))

            # Quick verification
            from backup_system import DatabaseBackupSystem
            backup_system = DatabaseBackupSystem()

            if not backup_system.verify_backup(backup_path):
                flash("‚ùå Backup file verification failed. Cannot restore.", "error")
                return redirect(url_for('backup_page'))

            # Perform restore with Flask application context
            def restore_with_app_context():
                try:
                    # Ensure we're within Flask application context
                    with app.app_context():
                        return backup_system.restore_backup(backup_path)
                except Exception as e:
                    logger.error(f"Restore error in thread: {e}")
                    return False

            # Start restore in background with timeout
            import concurrent.futures
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(restore_with_app_context)
                try:
                    # Wait up to 90 seconds for restore to complete (matching backend timeout)
                    result = future.result(timeout=90)
                    if result:
                        flash("‚úÖ Database restored successfully from backup. Archived items have been restored to their original locations.", "success")
                        # Log the restore activity
                        log_activity('restored', 'database', backup_file, f"Database restored from {backup_file}")
                    else:
                        flash("‚ùå Failed to restore backup. Check logs for details.", "error")
                except concurrent.futures.TimeoutError:
                    flash("‚ö†Ô∏è Restore operation timed out after 90 seconds. Please check if restore completed successfully.", "warning")
                except Exception as e:
                    flash(f"‚ùå Restore operation failed: {str(e)}", "error")

        except Exception as e:
            flash(f"‚ùå Error during restore process: {str(e)}", "error")
            logger.error(f"Backup restore error: {e}")

        return redirect(url_for('backup_page'))

    @app.route("/backup/cleanup", methods=["POST"])
    @admin_required
    def cleanup_backups():
        """Clean up old backups."""
        try:
            from backup_system import DatabaseBackupSystem
            backup_system = DatabaseBackupSystem()
            backup_system.cleanup_old_backups()
            flash("‚úÖ Old backups cleaned up successfully.", "success")
        except Exception as e:
            flash(f"‚ùå Error cleaning up backups: {str(e)}", "error")

        return redirect(url_for('backup_page'))

    @app.route("/backup/delete", methods=["POST"])
    @admin_required
    def delete_backup():
        """Delete a backup file permanently."""
        try:
            backup_filename = request.form.get('backup_file')
            if not backup_filename:
                flash("‚ùå No backup file specified.", "error")
                return redirect(url_for('backup_page'))

            from backup_system import DatabaseBackupSystem
            backup_system = DatabaseBackupSystem()

            # Get the backup file path
            backup_path = backup_system.backup_dir / backup_filename
            metadata_path = backup_path.with_suffix('.json')

            if not backup_path.exists():
                flash("‚ùå Backup file not found.", "error")
                return redirect(url_for('backup_page'))

            # Delete the backup file and its metadata
            backup_path.unlink()
            if metadata_path.exists():
                metadata_path.unlink()

            flash(f"‚úÖ Backup file '{backup_filename}' deleted successfully.", "success")

            # Log activity
            log_activity('deleted', 'backup_file', backup_filename, f"Backup: {backup_filename}")

        except Exception as e:
            flash(f"‚ùå Error deleting backup file: {str(e)}", "error")

        return redirect(url_for('backup_page'))

    @app.route("/archives")
    @admin_required
    def archives_page():
        """Display archived items management page."""
        try:
            # Get archived items with user info - using explicit aliases to avoid parameter conflicts
            archived_updates = db.session.query(
                ArchivedUpdate,
                user_alias.display_name.label('archived_by_name')
            ).outerjoin(
                user_alias, ArchivedUpdate.archived_by == user_alias.id
            ).order_by(ArchivedUpdate.archived_at.desc()).all()

            archived_sops = db.session.query(
                ArchivedSOPSummary,
                user_alias.display_name.label('archived_by_name')
            ).outerjoin(
                user_alias, ArchivedSOPSummary.archived_by == user_alias.id
            ).order_by(ArchivedSOPSummary.archived_at.desc()).all()

            archived_lessons = db.session.query(
                ArchivedLessonLearned,
                user_alias.display_name.label('archived_by_name')
            ).outerjoin(
                user_alias, ArchivedLessonLearned.archived_by == user_alias.id
            ).order_by(ArchivedLessonLearned.archived_at.desc()).all()

            return render_template('archives.html',
                                 app_name=app.config["APP_NAME"],
                                 archived_updates=archived_updates,
                                 archived_sops=archived_sops,
                                 archived_lessons=archived_lessons)
        except Exception as e:
            flash(f"‚ùå Error loading archives: {str(e)}", "error")
            return redirect(url_for('backup_page'))

    @app.route("/archives/restore/<item_type>/<item_id>", methods=["POST"])
    @admin_required
    def restore_archived_item(item_type, item_id):
        """Restore an archived item."""
        try:
            if item_type == 'update':
                # For updates, item_id is a string (UUID)
                archived_item = ArchivedUpdate.query.get(item_id)
                if archived_item:
                    # Create new update from archived data
                    restored_update = Update(
                        id=archived_item.id,
                        name=archived_item.name,
                        process=archived_item.process,
                        message=archived_item.message,
                        timestamp=archived_item.timestamp
                    )
                    db.session.add(restored_update)
                    db.session.delete(archived_item)
                    db.session.commit()
                    flash("‚úÖ Update restored successfully.", "success")

                    # Log activity
                    log_activity('restored', 'update', archived_item.id, f"Update: {archived_item.message[:50]}...")

            elif item_type == 'sop':
                # For SOPs, item_id is an integer
                try:
                    sop_id = int(item_id)
                    archived_item = ArchivedSOPSummary.query.get(sop_id)
                except ValueError:
                    flash("‚ùå Invalid SOP ID format.", "error")
                    return redirect(url_for('archives_page'))

                if archived_item:
                    restored_sop = SOPSummary(
                        title=archived_item.title,
                        summary_text=archived_item.summary_text,
                        department=archived_item.department,
                        tags=archived_item.tags,
                        created_at=archived_item.created_at
                    )
                    db.session.add(restored_sop)
                    db.session.delete(archived_item)
                    db.session.commit()
                    flash("‚úÖ SOP restored successfully.", "success")

                    # Log activity
                    log_activity('restored', 'sop', restored_sop.id, archived_item.title)

            elif item_type == 'lesson':
                # For lessons, item_id is an integer
                try:
                    lesson_id = int(item_id)
                    archived_item = ArchivedLessonLearned.query.get(lesson_id)
                except ValueError:
                    flash("‚ùå Invalid Lesson ID format.", "error")
                    return redirect(url_for('archives_page'))

                if archived_item:
                    restored_lesson = LessonLearned(
                        title=archived_item.title,
                        content=archived_item.content,
                        summary=archived_item.summary,
                        author=archived_item.author,
                        department=archived_item.department,
                        tags=archived_item.tags,
                        created_at=archived_item.created_at
                    )
                    db.session.add(restored_lesson)
                    db.session.delete(archived_item)
                    db.session.commit()
                    flash("‚úÖ Lesson Learned restored successfully.", "success")

                    # Log activity
                    log_activity('restored', 'lesson', restored_lesson.id, archived_item.title)

            else:
                flash("‚ùå Invalid item type.", "error")

        except Exception as e:
            db.session.rollback()
            flash(f"‚ùå Error restoring item: {str(e)}", "error")

        return redirect(url_for('archives_page'))

    @app.route("/archives/delete/<item_type>/<item_id>", methods=["POST"])
    @admin_required
    def delete_archived_item(item_type, item_id):
        """Permanently delete an archived item."""
        try:
            if item_type == 'update':
                # For updates, item_id is a string (UUID)
                archived_item = ArchivedUpdate.query.get(item_id)
                if archived_item:
                    entity_title = f"Update: {archived_item.message[:50]}..."
                    db.session.delete(archived_item)
                    db.session.commit()
                    flash("‚úÖ Archived update permanently deleted.", "success")

                    # Log activity
                    log_activity('permanently_deleted', 'archived_update', archived_item.id, entity_title)
                else:
                    flash("‚ùå Archived update not found.", "error")

            elif item_type == 'sop':
                # For SOPs, item_id is an integer
                try:
                    sop_id = int(item_id)
                    archived_item = ArchivedSOPSummary.query.get(sop_id)
                except ValueError:
                    flash("‚ùå Invalid SOP ID format.", "error")
                    return redirect(url_for('archives_page'))

                if archived_item:
                    entity_title = archived_item.title
                    db.session.delete(archived_item)
                    db.session.commit()
                    flash("‚úÖ Archived SOP permanently deleted.", "success")

                    # Log activity
                    log_activity('permanently_deleted', 'archived_sop', str(sop_id), entity_title)
                else:
                    flash("‚ùå Archived SOP not found.", "error")

            elif item_type == 'lesson':
                # For lessons, item_id is an integer
                try:
                    lesson_id = int(item_id)
                    archived_item = ArchivedLessonLearned.query.get(lesson_id)
                except ValueError:
                    flash("‚ùå Invalid lesson ID format.", "error")
                    return redirect(url_for('archives_page'))

                if archived_item:
                    entity_title = archived_item.title
                    db.session.delete(archived_item)
                    db.session.commit()
                    flash("‚úÖ Archived lesson permanently deleted.", "success")

                    # Log activity
                    log_activity('permanently_deleted', 'archived_lesson', str(lesson_id), entity_title)
                else:
                    flash("‚ùå Archived lesson not found.", "error")

            else:
                flash("‚ùå Invalid item type.", "error")

        except Exception as e:
            db.session.rollback()
            flash(f"‚ùå Error deleting archived item: {str(e)}", "error")

        return redirect(url_for('archives_page'))

    # Add cache control for static files to prevent 304 caching issues
    @app.after_request
    def add_cache_control(response):
        if request.path.startswith('/static/'):
            # Don't cache JS and CSS files in development
            if app.config.get('DEBUG', False) or os.getenv('FLASK_ENV') != 'production':
                if request.path.endswith(('.js', '.css')):
                    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
                    response.headers['Pragma'] = 'no-cache'
                    response.headers['Expires'] = '0'

        # Socket.IO CORS is handled by the Socket.IO extension, don't override here

        # Add Railway-specific headers (only essential ones in production)
        if os.getenv('RAILWAY_ENVIRONMENT'):
            is_production = os.getenv("RAILWAY_ENVIRONMENT") == "production" or os.getenv("FLASK_ENV") == "production"
            is_development = os.getenv("FLASK_ENV") == "development" or not is_production

            # Essential headers for all environments
            response.headers['X-Railway-Environment'] = os.getenv('RAILWAY_ENVIRONMENT')
            response.headers['X-SocketIO-Support'] = 'enabled'
            response.headers['X-WebSocket-Support'] = 'enabled'
            response.headers['X-Transport-Support'] = 'websocket,polling'
            response.headers['X-Server-Version'] = 'LoopIn-v1.0'

            # Add debug headers only in development
            if is_development:
                response.headers['X-Railway-Project-ID'] = os.getenv('RAILWAY_PROJECT_ID', '')
                response.headers['X-Railway-Service-ID'] = os.getenv('RAILWAY_SERVICE_ID', '')
                response.headers['X-Railway-Public-Domain'] = os.getenv('RAILWAY_PUBLIC_DOMAIN', '')
                response.headers['X-Railway-Git-Commit-SHA'] = os.getenv('RAILWAY_GIT_COMMIT_SHA', '')
                response.headers['X-Railway-Git-Branch'] = os.getenv('RAILWAY_GIT_BRANCH', '')
                response.headers['X-Debug-Mode'] = str(debug_mode).lower()
                response.headers['X-Timestamp'] = now_utc().isoformat()
                response.headers['X-Status'] = 'healthy'
                response.headers['X-Connection-Status'] = 'ready'
                response.headers['X-SocketIO-Version'] = '4.7.2'
                response.headers['X-Debug-Info'] = 'Socket.IO debugging enabled'

        return response

    return app

# Create app instance for gunicorn
app = create_app()

if __name__ == "__main__":
    port = int(os.getenv("PORT", 8000))
    # Set debug based on environment variable
    debug_mode = os.getenv("FLASK_DEBUG", "False").lower() == "true"

    if os.getenv("FLASK_ENV") == "development":
        print("üöÄ Starting LoopIn server...")
        print(f"üîå Socket.IO configured for port {port}")
        print(f"üåê Server will be available at: http://0.0.0.0:{port}")
        print(f"üîß Debug mode: {debug_mode}")

    try:
        # Use socketio.run for proper Socket.IO server startup
        if os.getenv("FLASK_ENV") == "development":
            print("üöÄ Starting Socket.IO server...")
        socketio.run(
            app,
            host="0.0.0.0",
            port=port,
            debug=debug_mode,
            log_output=debug_mode,
            use_reloader=debug_mode,
            # Additional Socket.IO server options for Railway compatibility
            keyfile=None,
            certfile=None,
            server_options={
                'ping_timeout': 60,
                'ping_interval': 25,
                'max_http_buffer_size': 1000000,
                'allow_upgrades': True,
                'transports': ['polling', 'websocket']
            }
        )
    except Exception as e:
        if os.getenv("FLASK_ENV") == "development":
            print(f"‚ùå Failed to start Socket.IO server: {e}")
            import traceback
            print(f"‚ùå Full Socket.IO error: {traceback.format_exc()}")
        # Fallback to regular Flask app if Socket.IO fails
        if os.getenv("FLASK_ENV") == "development":
            print("üîÑ Falling back to regular Flask app...")
        try:
            app.run(host="0.0.0.0", port=port, debug=debug_mode)
        except Exception as fallback_error:
            if os.getenv("FLASK_ENV") == "development":
                print(f"‚ùå Even fallback failed: {fallback_error}")
            raise
